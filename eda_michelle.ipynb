{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blThwcZo0Q-V"
   },
   "source": [
    "### Research questions\n",
    "1. prediction problem (classification) and feature weights - simply predict the next sentiment based on generated features, and analyse which feature contributes the most. examples: user-id (same thing) date (time), text (key words).\n",
    "2. incoperate with LLM to give explanations of why the text is classified as given sentiment.\n",
    "3. efficient forecasting over large datasets, create a basic model, and compared two ways of processing data. 1, deploy locally and use naive python packages. 2, utilize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1137,
     "status": "ok",
     "timestamp": 1744828695063,
     "user": {
      "displayName": "Michelle Tong",
      "userId": "01244029464473717573"
     },
     "user_tz": 240
    },
    "id": "gCxBRGXvwynN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/michelletong/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/michelletong/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/michelletong/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "from datetime import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GroupKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import multiprocessing\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "executionInfo": {
     "elapsed": 280,
     "status": "error",
     "timestamp": 1744828701560,
     "user": {
      "displayName": "Michelle Tong",
      "userId": "01244029464473717573"
     },
     "user_tz": 240
    },
    "id": "4XMFiO5Lw3RQ",
    "outputId": "0fd86710-1545-44ab-fb06-88c2fcbf0ed6"
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess the dataset\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(file_path, encoding='latin-1', header=None)\n",
    "    df.columns = ['sentiment', 'id', 'date', 'query', 'user', 'text']\n",
    "    \n",
    "    # Convert sentiment to binary (0: negative, 1: positive)\n",
    "    # Assuming sentiment values are 0 and 4 in the original dataset\n",
    "    df['sentiment'] = df['sentiment'].map({0: 0, 4: 1})\n",
    "    \n",
    "    # Convert date to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%a %b %d %H:%M:%S PDT %Y')\n",
    "    \n",
    "    # Extract basic features from text\n",
    "    df['text_length'] = df['text'].str.len()\n",
    "    df['word_count'] = df['text'].str.split().str.len()\n",
    "    df['hashtag_count'] = df['text'].str.count(r'#')\n",
    "    df['mention_count'] = df['text'].str.count(r'@')\n",
    "    df['url_count'] = df['text'].str.count(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\\\\\\\\\\\\\(\\\\\\\\\\\\\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    \n",
    "    # Extract time-based features\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['month'] = df['date'].dt.month\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Improved text cleaning function\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean the text data by removing @mentions, URLs, hashtags, punctuation\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Remove @mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    \n",
    "    # Remove hashtags (but keep the text after #)\n",
    "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "h0QoPhx7zY4r"
   },
   "outputs": [],
   "source": [
    "def create_visualizations(df):\n",
    "    # 1. Sentiment Distribution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.countplot(x='sentiment', data=df)\n",
    "    plt.title('Distribution of Sentiments')\n",
    "    plt.xlabel('Sentiment')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks([0, 1], ['Negative', 'Positive'])\n",
    "    plt.savefig('sentiment_distribution.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Text Length Distribution by Sentiment\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='sentiment', y='text_length', data=df)\n",
    "    plt.title('Text Length Distribution by Sentiment')\n",
    "    plt.xlabel('Sentiment')\n",
    "    plt.ylabel('Text Length')\n",
    "    plt.xticks([0, 1], ['Negative', 'Positive'])\n",
    "    plt.savefig('text_length_distribution.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Time-based Analysis\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Hourly distribution\n",
    "    sns.countplot(x='hour', hue='sentiment', data=df, ax=axes[0])\n",
    "    axes[0].set_title('Tweets by Hour of Day')\n",
    "    axes[0].set_xlabel('Hour')\n",
    "    axes[0].set_ylabel('Count')\n",
    "    axes[0].legend(title='Sentiment', labels=['Negative', 'Positive'])\n",
    "    \n",
    "    # Day of week distribution\n",
    "    sns.countplot(x='day_of_week', hue='sentiment', data=df, ax=axes[1])\n",
    "    axes[1].set_title('Tweets by Day of Week')\n",
    "    axes[1].set_xlabel('Day of Week (0=Monday)')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].legend(title='Sentiment', labels=['Negative', 'Positive'])\n",
    "    \n",
    "    # Monthly distribution\n",
    "    sns.countplot(x='month', hue='sentiment', data=df, ax=axes[2])\n",
    "    axes[2].set_title('Tweets by Month')\n",
    "    axes[2].set_xlabel('Month')\n",
    "    axes[2].set_ylabel('Count')\n",
    "    axes[2].legend(title='Sentiment', labels=['Negative', 'Positive'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('time_based_analysis.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Feature Correlation Analysis\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    correlation_matrix = df[['sentiment', 'text_length', 'word_count', 'hashtag_count', 'mention_count', 'url_count']].corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.savefig('feature_correlation.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Word Clouds for Positive and Negative Tweets\n",
    "    def generate_wordcloud(text, title, filename):\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(title)\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "    \n",
    "    # Generate word clouds for positive and negative tweets\n",
    "    positive_text = ' '.join(df[df['sentiment'] == 1]['text'])\n",
    "    negative_text = ' '.join(df[df['sentiment'] == 0]['text'])\n",
    "    \n",
    "    generate_wordcloud(positive_text, 'Word Cloud for Positive Tweets', 'positive_wordcloud.png')\n",
    "    generate_wordcloud(negative_text, 'Word Cloud for Negative Tweets', 'negative_wordcloud.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"\n",
    "    Engineer features based on the project outline\n",
    "    \"\"\"\n",
    "    # 1. User-based Features\n",
    "    \n",
    "    # Group by user and calculate statistics\n",
    "    user_stats = df.groupby('user')['sentiment'].agg(['mean', 'count', 'std']).reset_index()\n",
    "    \n",
    "    # Calculate correct std with n-1 denominator\n",
    "    def adjusted_std(group):\n",
    "        if len(group) <= 1:\n",
    "            return 0\n",
    "        return np.std(group, ddof=1)  # ddof=1 uses n-1 denominator\n",
    "    \n",
    "    user_sentiment_std = df.groupby('user')['sentiment'].apply(adjusted_std)\n",
    "    user_stats['std'] = user_stats['user'].map(user_sentiment_std)\n",
    "    \n",
    "    # Handle case where a user has only one tweet (std is NaN)\n",
    "    user_stats['std'] = user_stats['std'].fillna(0)\n",
    "    \n",
    "    user_stats.columns = ['user', 'user_avg_sentiment', 'user_tweet_count', 'user_sentiment_std']\n",
    "    \n",
    "    # Merge user stats back to main dataframe\n",
    "    df = pd.merge(df, user_stats, on='user', how='left')\n",
    "    \n",
    "    # Calculate average posting gap time for each user\n",
    "    df = df.sort_values(['user', 'date'])\n",
    "    \n",
    "    # Function to calculate average time between posts\n",
    "    def calc_avg_gap(group):\n",
    "        if len(group) <= 1:\n",
    "            return pd.Timedelta(0)\n",
    "        gaps = group['date'].diff().dropna()\n",
    "        return gaps.mean()\n",
    "    \n",
    "    # Calculate average gap for each user\n",
    "    avg_gaps = df.groupby('user').apply(calc_avg_gap)\n",
    "    avg_gaps_seconds = avg_gaps.dt.total_seconds()\n",
    "    avg_gaps_df = pd.DataFrame({\n",
    "        'user': avg_gaps.index, \n",
    "        'avg_posting_gap_seconds': avg_gaps_seconds.values\n",
    "    })\n",
    "    \n",
    "    # Merge gaps back to main dataframe\n",
    "    df = pd.merge(df, avg_gaps_df, on='user', how='left')\n",
    "    df['avg_posting_gap_seconds'] = df['avg_posting_gap_seconds'].fillna(0)\n",
    "    \n",
    "    # 2. Text Processing Features\n",
    "    \n",
    "    # Apply text cleaning\n",
    "    df['clean_text'] = df['text'].apply(clean_text)\n",
    "    \n",
    "    # Create tokenized text for Word2Vec\n",
    "    df['tokens'] = df['clean_text'].apply(word_tokenize)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df['tokens'] = df['tokens'].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_word2vec_features(df, vector_size=100):\n",
    "    \"\"\"\n",
    "    Extract Word2Vec features\n",
    "    \"\"\"\n",
    "    # Train Word2Vec model\n",
    "    all_tokens = df['tokens'].tolist()\n",
    "    w2v_model = Word2Vec(\n",
    "        sentences=all_tokens,\n",
    "        vector_size=vector_size,\n",
    "        window=5,\n",
    "        min_count=1,\n",
    "        workers=4\n",
    "    )\n",
    "    \n",
    "    # Function to get document vectors by averaging word vectors\n",
    "    def get_doc_vector(tokens):\n",
    "        vec = np.zeros(vector_size)\n",
    "        count = 0\n",
    "        for word in tokens:\n",
    "            try:\n",
    "                vec += w2v_model.wv[word]\n",
    "                count += 1\n",
    "            except KeyError:\n",
    "                # Word not in vocabulary\n",
    "                continue\n",
    "        if count > 0:\n",
    "            vec /= count\n",
    "        return vec\n",
    "    \n",
    "    # Get document vectors\n",
    "    doc_vectors = np.array(df['tokens'].apply(get_doc_vector).tolist())\n",
    "    w2v_df = pd.DataFrame(\n",
    "        doc_vectors,\n",
    "        columns=[f'w2v_{i}' for i in range(vector_size)]\n",
    "    )\n",
    "    \n",
    "    return w2v_df, w2v_model\n",
    "\n",
    "def select_features(features_df, n_components=50):\n",
    "    \"\"\"\n",
    "    Perform PCA for feature selection\n",
    "    \"\"\"\n",
    "    # Initialize PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    \n",
    "    # Fit and transform\n",
    "    pca_features = pca.fit_transform(features_df)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    pca_df = pd.DataFrame(\n",
    "        pca_features, \n",
    "        columns=[f'pca_{i}' for i in range(n_components)]\n",
    "    )\n",
    "    \n",
    "    # Calculate explained variance ratio\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    cumulative_variance = np.cumsum(explained_variance)\n",
    "    \n",
    "    # Print variance explanation\n",
    "    print(f\"Top 10 components explain {cumulative_variance[9]:.2%} of variance\")\n",
    "    print(f\"All {n_components} components explain {cumulative_variance[-1]:.2%} of variance\")\n",
    "    \n",
    "    return pca_df, pca\n",
    "\n",
    "def train_evaluate_models(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Train and evaluate classification models\n",
    "    \"\"\"\n",
    "    # Define base models\n",
    "    svm = SVC(probability=True, kernel='rbf')\n",
    "    rf = RandomForestClassifier(n_estimators=100)\n",
    "    xgb = GradientBoostingClassifier(n_estimators=100)\n",
    "    \n",
    "    # Train individual models\n",
    "    models = {\n",
    "        'SVM': svm,\n",
    "        'Random Forest': rf,\n",
    "        'XGBoost': xgb\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        class_report = classification_report(y_test, y_pred)\n",
    "        \n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'confusion_matrix': conf_matrix,\n",
    "            'classification_report': class_report\n",
    "        }\n",
    "        \n",
    "        print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "        print(f\"Classification Report:\\n{class_report}\")\n",
    "        print(\"=\"*50)\n",
    "    \n",
    "    # Create Voting Ensemble (majority voting)\n",
    "    voting_clf = VotingClassifier(\n",
    "        estimators=[('svm', svm), ('rf', rf), ('xgb', xgb)],\n",
    "        voting='hard'  # Majority voting\n",
    "    )\n",
    "    \n",
    "    print(\"Training Ensemble (Majority Voting)...\")\n",
    "    voting_clf.fit(X_train, y_train)\n",
    "    y_pred = voting_clf.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    results['Ensemble'] = {\n",
    "        'model': voting_clf,\n",
    "        'accuracy': accuracy,\n",
    "        'confusion_matrix': conf_matrix,\n",
    "        'classification_report': class_report\n",
    "    }\n",
    "    \n",
    "    print(f\"Ensemble Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "    print(f\"Classification Report:\\n{class_report}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def perform_cross_validation(X, y, df):\n",
    "    \"\"\"\n",
    "    Perform time-based and user-based cross-validation\n",
    "    \"\"\"\n",
    "    # Time-based Cross Validation\n",
    "    print(\"Performing Time-based Cross Validation\")\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    # Use SVM as model for validation\n",
    "    model = SVC(kernel='rbf')\n",
    "    \n",
    "    time_scores = []\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "        time_scores.append(score)\n",
    "    \n",
    "    print(f\"Time-based CV Scores: {time_scores}\")\n",
    "    print(f\"Mean Time-based CV Score: {np.mean(time_scores):.4f}\")\n",
    "    \n",
    "    # User-based Cross Validation\n",
    "    print(\"\\nPerforming User-based Cross Validation\")\n",
    "    user_groups = df['user'].astype('category').cat.codes.values\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    \n",
    "    user_scores = []\n",
    "    for train_index, test_index in gkf.split(X, y, groups=user_groups):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "        user_scores.append(score)\n",
    "    \n",
    "    print(f\"User-based CV Scores: {user_scores}\")\n",
    "    print(f\"Mean User-based CV Score: {np.mean(user_scores):.4f}\")\n",
    "    \n",
    "    return time_scores, user_scores\n",
    "\n",
    "def analyze_misclassified_examples(df, X_test, y_test, model, idx_test):\n",
    "    \"\"\"\n",
    "    Analyze misclassified examples\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    misclassified_idx = idx_test[y_pred != y_test]\n",
    "    \n",
    "    misclassified_df = df.iloc[misclassified_idx].copy()\n",
    "    misclassified_df['predicted_sentiment'] = y_pred[y_pred != y_test]\n",
    "    \n",
    "    print(f\"Number of misclassified examples: {len(misclassified_df)}\")\n",
    "    \n",
    "    # Analyze by features\n",
    "    print(\"\\nMisclassification Analysis by Features:\")\n",
    "    \n",
    "    # By text length\n",
    "    print(\"\\nBy Text Length:\")\n",
    "    bins = [0, 50, 100, 150, 200, np.inf]\n",
    "    labels = ['Very Short', 'Short', 'Medium', 'Long', 'Very Long']\n",
    "    misclassified_df['text_length_bin'] = pd.cut(misclassified_df['text_length'], bins=bins, labels=labels)\n",
    "    print(misclassified_df['text_length_bin'].value_counts(normalize=True).sort_index())\n",
    "    \n",
    "    # By user tweet count\n",
    "    print(\"\\nBy User Tweet Count:\")\n",
    "    bins = [0, 5, 10, 20, 50, np.inf]\n",
    "    labels = ['Very Few', 'Few', 'Average', 'Many', 'Very Many']\n",
    "    misclassified_df['user_tweet_count_bin'] = pd.cut(misclassified_df['user_tweet_count'], bins=bins, labels=labels)\n",
    "    print(misclassified_df['user_tweet_count_bin'].value_counts(normalize=True).sort_index())\n",
    "    \n",
    "    # By time of day\n",
    "    print(\"\\nBy Hour of Day:\")\n",
    "    hour_bins = [0, 6, 12, 18, 24]\n",
    "    hour_labels = ['Night', 'Morning', 'Afternoon', 'Evening']\n",
    "    misclassified_df['hour_bin'] = pd.cut(misclassified_df['hour'], bins=hour_bins, labels=hour_labels)\n",
    "    print(misclassified_df['hour_bin'].value_counts(normalize=True).sort_index())\n",
    "    \n",
    "    # Sample of misclassified examples\n",
    "    print(\"\\nSample of Misclassified Examples:\")\n",
    "    sample = misclassified_df.sample(min(5, len(misclassified_df)))\n",
    "    for _, row in sample.iterrows():\n",
    "        print(f\"Text: {row['text']}\")\n",
    "        print(f\"True Sentiment: {row['sentiment']}, Predicted: {row['predicted_sentiment']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    return misclassified_df\n",
    "\n",
    "def visualize_results(df, results, pca, feature_names):\n",
    "    \"\"\"\n",
    "    Create visualizations for the analysis\n",
    "    \"\"\"\n",
    "    # 1. PCA Explained Variance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)\n",
    "    plt.xlabel('Principal Component')\n",
    "    plt.ylabel('Explained Variance Ratio')\n",
    "    plt.title('Explained Variance by Principal Component')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pca_variance.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Feature Importance from PCA loadings\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    # Get most important features from first component\n",
    "    component = 0\n",
    "    loadings = pd.Series(abs(pca.components_[component]), index=feature_names)\n",
    "    top_features = loadings.nlargest(15)\n",
    "    \n",
    "    sns.barplot(x=top_features.values, y=top_features.index)\n",
    "    plt.title(f'Top 15 Feature Importances (PC {component+1})')\n",
    "    plt.xlabel('Absolute Loading Value')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Sentiment Distribution by Time of Day\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    hour_counts = df.groupby(['hour', 'sentiment']).size().unstack()\n",
    "    hour_counts.plot(kind='bar', stacked=True)\n",
    "    plt.title('Sentiment Distribution by Hour of Day')\n",
    "    plt.xlabel('Hour')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend(['Negative', 'Positive'])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sentiment_by_hour.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Sentiment Distribution by Day of Week\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    day_counts = df.groupby(['day_of_week', 'sentiment']).size().unstack()\n",
    "    day_counts.plot(kind='bar', stacked=True)\n",
    "    plt.title('Sentiment Distribution by Day of Week')\n",
    "    plt.xlabel('Day of Week (0=Monday)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend(['Negative', 'Positive'])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('sentiment_by_day.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. User Sentiment Patterns (Top 10 users by tweet count)\n",
    "    top_users = df['user'].value_counts().head(10).index\n",
    "    user_df = df[df['user'].isin(top_users)]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    user_sentiment = user_df.groupby('user')['sentiment'].mean().sort_values()\n",
    "    sns.barplot(x=user_sentiment.index, y=user_sentiment.values)\n",
    "    plt.title('Average Sentiment for Top 10 Users')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('user_sentiment.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 6. Word Clouds by Sentiment\n",
    "    for sentiment, label in [(0, 'Negative'), (1, 'Positive')]:\n",
    "        text = ' '.join(df[df['sentiment'] == sentiment]['clean_text'])\n",
    "        \n",
    "        wordcloud = WordCloud(\n",
    "            width=800, height=400,\n",
    "            background_color='white',\n",
    "            max_words=200\n",
    "        ).generate(text)\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Word Cloud for {label} Sentiment')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'wordcloud_sentiment_{sentiment}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # 7. Model Comparison\n",
    "    accuracies = {name: info['accuracy'] for name, info in results.items()}\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()))\n",
    "    plt.title('Model Accuracy Comparison')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 8. Confusion Matrix Visualization\n",
    "    for name, info in results.items():\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        cm = info['confusion_matrix']\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                   xticklabels=['Negative', 'Positive'],\n",
    "                   yticklabels=['Negative', 'Positive'])\n",
    "        plt.title(f'Confusion Matrix - {name}')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'confusion_matrix_{name}.png')\n",
    "        plt.close()\n",
    "\n",
    "def compare_processing_methods(df, test_size=1000):\n",
    "    \"\"\"\n",
    "    Compare local vs distributed processing performance\n",
    "    \"\"\"\n",
    "    # Subset data for testing\n",
    "    test_df = df.sample(test_size, random_state=42)\n",
    "    \n",
    "    # 1. Local Python Implementation\n",
    "    print(\"Testing Local Python Implementation...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Simulate local processing\n",
    "    tokens = test_df['text'].apply(clean_text).apply(word_tokenize).tolist()\n",
    "    local_time = time.time() - start_time\n",
    "    print(f\"Local processing time: {local_time:.2f} seconds\")\n",
    "    \n",
    "    # 2. Simulated Distributed Processing\n",
    "    try:\n",
    "        print(\"\\nTesting Parallel Processing Implementation...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Determine number of cores\n",
    "        num_cores = multiprocessing.cpu_count()\n",
    "        print(f\"Using {num_cores} cores\")\n",
    "        \n",
    "        # Split data into chunks\n",
    "        chunks = np.array_split(test_df['text'], num_cores)\n",
    "        \n",
    "        # Define processing function\n",
    "        def process_chunk(chunk):\n",
    "            return [word_tokenize(clean_text(text)) for text in chunk]\n",
    "        \n",
    "        # Create a pool and process in parallel\n",
    "        with multiprocessing.Pool(num_cores) as pool:\n",
    "            results = pool.map(process_chunk, chunks)\n",
    "            \n",
    "        # Flatten results\n",
    "        parallel_tokens = [item for sublist in results for item in sublist]\n",
    "        \n",
    "        parallel_time = time.time() - start_time\n",
    "        print(f\"Parallel processing time: {parallel_time:.2f} seconds\")\n",
    "        print(f\"Speedup: {local_time / parallel_time:.2f}x\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in parallel processing: {e}\")\n",
    "        print(\"Please set up a proper distributed environment for actual testing\")\n",
    "        parallel_time = None\n",
    "    \n",
    "    return {'local_time': local_time, 'parallel_time': parallel_time}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading and preprocessing data...\")\n",
    "df = load_and_preprocess_data('sentiment140.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic statistics:\n",
      "Dataset shape: (1600000, 14)\n",
      "Sentiment distribution: sentiment\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBasic statistics:\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Sentiment distribution: {df['sentiment'].value_counts(normalize=True)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Engineering features...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEngineering features...\")\n",
    "df = engineer_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nExtracting Word2Vec features...\")\n",
    "w2v_df, w2v_model = extract_word2vec_features(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine numeric features with text features\n",
    "numeric_features = df[['text_length', 'word_count', 'hashtag_count', \n",
    "                        'mention_count', 'url_count', 'hour', 'day_of_week', \n",
    "                        'month', 'user_avg_sentiment', 'user_tweet_count', \n",
    "                        'user_sentiment_std', 'avg_posting_gap_seconds']]\n",
    "\n",
    "# Reset index to ensure proper concatenation\n",
    "numeric_features = numeric_features.reset_index(drop=True)\n",
    "w2v_df = w2v_df.reset_index(drop=True)\n",
    "\n",
    "# Combine all features\n",
    "all_features = pd.concat([numeric_features, w2v_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nPerforming feature selection with PCA...\")\n",
    "feature_names = all_features.columns\n",
    "pca_df, pca = select_features(all_features)\n",
    "\n",
    "# Define target variable\n",
    "y = df['sentiment']\n",
    "\n",
    "# Split data (keeping track of original indices)\n",
    "df_index = df.index\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    pca_df, y, df_index, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining and evaluating models...\")\n",
    "results = train_evaluate_models(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPerforming cross-validation...\")\n",
    "time_scores, user_scores = perform_cross_validation(pca_df, y, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAnalyzing misclassified examples...\")\n",
    "best_model_name = max(results.items(), key=lambda x: x[1]['accuracy'])[0]\n",
    "best_model = results[best_model_name]['model']\n",
    "misclassified_df = analyze_misclassified_examples(df, X_test, y_test, best_model, idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCreating visualizations...\")\n",
    "visualize_results(df, results, pca, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nComparing processing methods...\")\n",
    "performance_results = compare_processing_methods(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "sentiment_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
